{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84495c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Desktop\\IITM AI\\llm-applications-module-4\\RAG\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Langchain Simple Agent\n",
    "\n",
    "# Import required libraries\n",
    "\n",
    "# For calling the Openai API\n",
    "from langchain_openai import ChatOpenAI # LLM BRAIN - ENGINE\n",
    "# # For calling the Anthropic API\n",
    "# from langchain_anthropic import AnthropicChat\n",
    "# # For Azure OpenAI API\n",
    "# from langchain_azure_openai import AzureChatOpenAI\n",
    "# # For calling the Google API\n",
    "# from langchain_google import ChatGoogle\n",
    "# # For calling the Ollama API\n",
    "# from langchain_ollama import OllamaChat\n",
    "# # For calling the Cohere API\n",
    "# from langchain_cohere import CohereChat\n",
    "# # For calling the HuggingFace API\n",
    "# from langchain_huggingface import HuggingFaceChat\n",
    "# # For calling the Google Gemini API\n",
    "# from langchain_gemini import GeminiChat\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder # MESSAGES - CHASSIS\n",
    "# ChatPromptTemplate: It is used to create a prompt template for chat models. This helps in structuring the input for the model.\n",
    "# MessagesPlaceholder: It is used to create a placeholder for messages in the prompt template.\n",
    "\n",
    "from langchain.tools import tool # HANDS - DASHBOARD\n",
    "# tool: It is used to define a tool that can be called by the agent. This allows the agent to perform specific actions or retrieve information.\n",
    "\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "# create_tool_calling_agent: It is used to create an agent that can call tools.\n",
    "# AgentExecutor: It is used to execute the agent with the provided tools and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da670ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.document_loaders import PyPDFLoader # a class used to load text from PDF files\n",
    "\n",
    "# Imports a powerful text-splitting tool that breaks large documents into manageable chunks for embedding.\n",
    "# LLMs have context length limits, so splitting documents into chunks is essential.\n",
    "# Why recursive?\n",
    "# It tries to split at logical boundaries (like paragraphs, sentences, etc.) before falling back to raw character limits.\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# OpenAIEmbeddings - to convert text into vector format using OpenAI’s embedding API\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "\n",
    "from langchain.vectorstores import FAISS # a fast in-memory vector search engine used for semantic search.\n",
    "\n",
    "\"\"\"Imports RetrievalQA, a chain that connects:\n",
    "-A retriever (like FAISS)\n",
    "-A language model (like GPT): To answer questions using retrieved context.\n",
    "\n",
    "This is the heart of a RAG system — combining search + generation\"\"\"\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab39cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load environment variables from a .env file and set up API keys and other configurations\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8462b98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 24 pages from the document.\n"
     ]
    }
   ],
   "source": [
    "#step 2: Load and preprocess the document\n",
    "pdf_path = \"docs/sirca-hr.pdf\"\n",
    "\n",
    "try:\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    documents = loader.load()\n",
    "    print(f\"Loaded {len(documents)} pages from the document.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading document: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4ab161e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split document into 122 chunks.\n",
      "page_content='SPIL Corporate HR Policies  \n",
      " \n",
      " \n",
      "SIRCA PAINTS INDIA LTD \n",
      "NEW DELHI  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "CORPORATE  \n",
      "  HUMAN RESOURCES \n",
      "POLICIES & MANUALS' metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2020-08-26T06:56:00+00:00', 'author': 'hr', 'moddate': '2020-08-26T06:56:00+00:00', 'source': 'docs/sirca-hr.pdf', 'total_pages': 24, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "#step 3: Split the document into smaller chunks for processing\n",
    "#RecursiveCharacter text splitter tries to split at logical boundaries (like paragraphs, sentences, etc.) before falling back to raw character limits.\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,  # Maximum size of each chunk\n",
    "    chunk_overlap=100  # Overlap between chunks to maintain context\n",
    ")\n",
    "#chunk has text , vector representation and metadata\n",
    "#chuking is important because LLMs have context length limits\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"Split document into {len(chunks)} chunks.\")\n",
    "print(chunks[0])  # Print the first chunk to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b56d7fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-embedding-ada-002\n"
     ]
    }
   ],
   "source": [
    "#Step 4 : Create embeddings for the chunks using OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY) #text-embedding-ada-002\n",
    "\n",
    "print(embeddings.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6697a4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created with FAISS.\n"
     ]
    }
   ],
   "source": [
    "#step 5: Create a vector store using FAISS to store and retrieve embeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "vector_store = FAISS.from_documents(chunks, embeddings)\n",
    "print(\"Vector store created with FAISS.\")\n",
    "#save the vector store to disk\n",
    "#vector_store.save_local(\"faiss_index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3075775c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG chain created.\n"
     ]
    }
   ],
   "source": [
    "#step 6: Create a RetrievalQA chain that uses the vector store to answer questions\n",
    "llm = ChatOpenAI(model_name=\"gpt-4-turbo\", openai_api_key=OPENAI_API_KEY)\n",
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "#available search types: similarity, mmr, hybrid\n",
    "\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm, # LLM model\n",
    "    retriever=retriever,# Retriever to fetch relevant documents\n",
    "    return_source_documents=False # Whether to return source documents along with the answer\n",
    ")\n",
    "print(\"RAG chain created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2dc782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question: str):\n",
    "    \"\"\"Function to answer a question using the RAG chain.\"\"\"\n",
    "    result = rag_chain.invoke({\"query\":  question})\n",
    "    answer = result['result']\n",
    "    #source_docs = result['source_documents']\n",
    "    \n",
    "    print(f\"Question: {question}\\n\")\n",
    "    print(f\"Answer: {answer}\\n\")\n",
    "    #print(\"Source Documents:\")\n",
    "    #for i, doc in enumerate(source_docs):\n",
    "     #   print(f\"Document {i+1}:\\n{doc.page_content}\\n\")\n",
    "    \n",
    "   # return answer, #source_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66c5b227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the key responsibilities of the HR department as mentioned in the document?\n",
      "\n",
      "Answer: The key responsibilities of the HR department mentioned in the document include:\n",
      "\n",
      "1. Initiating and managing the recruitment process by sourcing candidates from various channels such as employment sites, internal job postings, referral schemes, campus recruitment, and placement agencies.\n",
      "2. Working with department heads to identify staffing needs based on project requirements.\n",
      "3. Ensuring proper documentation and statutory forms are completed by new hires on their joining date.\n",
      "4. Overseeing the induction and on-boarding process for new employees.\n",
      "\n",
      "These responsibilities focus on efficiently staffing the organization and ensuring that processes like onboarding and documentation are handled effectively to support the company's growth and adherence to internal policies.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#step 7: Test the RAG system with a sample question\n",
    "sample_question = \"What are the key responsibilities of the HR department as mentioned in the document?\"\n",
    "answer_question(sample_question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80b629e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What does SPIL stand for?\n",
      "\n",
      "Answer: SPIL stands for Sirca Paints India Limited.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ask another question\n",
    "another_question = \"What does SPIL stand for?\"\n",
    "answer_question(another_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "648a1fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what are the working hours mentioned in the document?\n",
      "\n",
      "Answer: The working hours mentioned in the document are:\n",
      "- 9:30 AM to 6:00 PM\n",
      "- 10:00 AM to 6:30 PM\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"what are the working hours mentioned in the document?\"\n",
    "answer_question(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
